<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Hadoop 集群搭建教程 - 邵溧崟的博客</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="邵溧崟" /><meta name="description" content="这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。
搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。
" /><meta name="keywords" content="Hadoop, 云计算, Setup Guide" />






<meta name="generator" content="Hugo 0.67.1 with theme even" />


<link rel="canonical" href="https://shaoliyin.me/post/hadoop-cluster-setup/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Hadoop 集群搭建教程" />
<meta property="og:description" content="这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。
搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shaoliyin.me/post/hadoop-cluster-setup/" />
<meta property="article:published_time" content="2019-05-29T19:38:06+08:00" />
<meta property="article:modified_time" content="2019-05-29T19:38:06+08:00" />
<meta itemprop="name" content="Hadoop 集群搭建教程">
<meta itemprop="description" content="这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。
搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。">
<meta itemprop="datePublished" content="2019-05-29T19:38:06&#43;08:00" />
<meta itemprop="dateModified" content="2019-05-29T19:38:06&#43;08:00" />
<meta itemprop="wordCount" content="2266">



<meta itemprop="keywords" content="Hadoop,云计算,Setup Guide," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Hadoop 集群搭建教程"/>
<meta name="twitter:description" content="这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。
搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">邵溧崟的博客</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">邵溧崟的博客</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Hadoop 集群搭建教程</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-05-29 </span>
        <div class="post-category">
            <a href="/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
            </div>
          <span class="more-meta"> 约 2266 字 </span>
          <span class="more-meta"> 预计阅读 5 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-先决条件">1 先决条件</a></li>
    <li><a href="#2-下载二进制文件">2 下载二进制文件</a></li>
    <li><a href="#3-修改配置文件">3 修改配置文件</a>
      <ul>
        <li><a href="#31-core-sitexml">3.1 core-site.xml</a></li>
        <li><a href="#32-hdfs-sitexml">3.2 hdfs-site.xml</a></li>
        <li><a href="#33-mapred-sitexml">3.3 mapred-site.xml</a></li>
        <li><a href="#34-yarnxml">3.4 yarn.xml</a></li>
        <li><a href="#35-slaves">3.5 slaves</a></li>
        <li><a href="#36-hadoop-envsh">3.6 hadoop-env.sh</a></li>
      </ul>
    </li>
    <li><a href="#4-分发配置文件">4 分发配置文件</a></li>
    <li><a href="#5-启动集群">5 启动集群</a>
      <ul>
        <li><a href="#51-格式化-hdfs">5.1 格式化 HDFS</a></li>
        <li><a href="#52-启动集群">5.2 启动集群</a></li>
      </ul>
    </li>
    <li><a href="#6-提交示例任务">6 提交示例任务</a></li>
    <li><a href="#7-遇到的坑">7 遇到的坑</a>
      <ul>
        <li><a href="#71-hostname-配置">7.1 hostname 配置</a></li>
        <li><a href="#72-format-命令">7.2 format 命令</a></li>
        <li><a href="#73-日志">7.3 日志</a></li>
        <li><a href="#74-配置文件的同步">7.4 配置文件的同步</a></li>
      </ul>
    </li>
    <li><a href="#8-参考">8 参考</a></li>
  </ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="2019-05-29T19:38:06" title="May 29, 2019">May 29, 2019</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      <p>这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。</p>
<p>搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。</p>
<h2 id="1-先决条件">1 先决条件</h2>
<p>在开始安装 Hadoop 之前，请确认集群的每台机器上均已安装 JDK1.8（注意是 SunJDK 而不是 OpenJDK），并且已经配置好密钥登陆（服务器两两之间可以无密码SSH登陆）。</p>
<p>除此之外还需要在三台机器的 <code>/etc/hosts</code> 文件中写入以下内容（需要root权限）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-text" data-lang="text">192.168.105.10 ivic10
192.168.105.11 ivic11
192.168.105.12 ivic12
</code></pre></td></tr></table>
</div>
</div><p>配置好以后，在任意一台机器上可以用 hostname 无密码 SSH 登陆到另外两台机器上</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 在ivic10上操作</span>
ssh ivic11
<span class="c1"># 如果一切正常，应该可以直接登陆到ivic11上</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="2-下载二进制文件">2 下载二进制文件</h2>
<p>在 Hadoop 的 <a href="https://hadoop.apache.org/releases.html">release</a> 页面中有数个版本可以选择，因为后续要在 Hadoop 集群上部署其他应用，所以这里选择兼容性最好的 2.7.7 版本。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">mkdir ~/bigdata
<span class="nb">cd</span> ~/bigdata
<span class="c1"># Apache网站上的镜像太慢，从清华镜像下载</span>
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
<span class="c1"># 解压到当前文件夹</span>
tar -xzvf hadoop-2.7.7.tar.gz -C .
</code></pre></td></tr></table>
</div>
</div><h2 id="3-修改配置文件">3 修改配置文件</h2>
<p>首先在 <code>~/.profile</code> 中添加环境变量</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">export</span> <span class="nv">HADOOP_HOME</span><span class="o">=</span>/home/ivic/bigdata/hadoop-2.7.7
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/bin
</code></pre></td></tr></table>
</div>
</div><p>用 <code>source</code> 命令让环境变量立即生效</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">source</span> ~/.profile
</code></pre></td></tr></table>
</div>
</div><p>然后切换到 Hadoop 的配置文件目录下，开始修改 Hadoop 的配置文件 <code>cd ~/bigdata/hadoop-2.7.7/etc/hadoop</code>，每一个配置项代表的意义可以参考文末给出的 Hadoop 官方文档。</p>
<h3 id="31-core-sitexml">3.1 core-site.xml</h3>
<p>通过<code>fs.defaultFS</code>指定 NameNode 的 IP 地址和端口号，通过<code>hadoop.tmp.dir</code>指定临时文件存放路径</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://ivic10:9000/<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>file:/tmp/hadoop-2.7.7<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="32-hdfs-sitexml">3.2 hdfs-site.xml</h3>
<p><code>dfs.replication</code> 指定备份数目为 3，<code>dfs.name.dir</code> 指定 NameNode 的文件存储路径，<code>dfs.data.dir</code> 指定 DataNode 的文件存储路径。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>3<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>file:/home/ivic/bigdata/hdfs/name<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>file:/home/ivic/bigdata/hdfs/data<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="33-mapred-sitexml">3.3 mapred-site.xml</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 将mapred-site.xml.template复制一份</span>
cp mapred-site.xml.template mapreduce-site.xml
</code></pre></td></tr></table>
</div>
</div><p>然后修改 <code>mapred-site.xml</code> 的内容</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="34-yarnxml">3.4 yarn.xml</h3>
<p>配置后两项是因为在部署 Flink on Yarn 的过程中出现了 FlinkYarnSession 无法启动的问题，从 StackOverflow 得知应该在此处加上这两项配置，否则虚拟内存占用会超出限制导致 Flink 无法启动。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-xml" data-lang="xml"><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>ivic10<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>false<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;description&gt;</span>Whether virtual memory limits will be enforced for containers<span class="nt">&lt;/description&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>4<span class="nt">&lt;/value&gt;</span>
        <span class="nt">&lt;description&gt;</span>Ratio between virtual memory to physical memory when setting memory limits for containers<span class="nt">&lt;/description&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="35-slaves">3.5 slaves</h3>
<p>添加 slave 节点的 hostname 到该文件中</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-text" data-lang="text">ivic11
ivic12
</code></pre></td></tr></table>
</div>
</div><h3 id="36-hadoop-envsh">3.6 hadoop-env.sh</h3>
<p>在这里为 Hadoop 设置环境变量</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/local/jdk1.8.0_201
</code></pre></td></tr></table>
</div>
</div><h2 id="4-分发配置文件">4 分发配置文件</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 需要先在11/12节点上建立 /homne/ivic/bigdata/ 文件夹</span>
scp -r /home/ivic/bigdata/hadoop-2.7.7 192.168.105.11:/home/ivic/bigdata/hadoop-2.7.7
scp -r /home/ivic/bigdata/hadoop-2.7.7 192.168.105.12:/home/ivic/bigdata/hadoop-2.7.7
</code></pre></td></tr></table>
</div>
</div><p>然后分别在其他节点上配置环境变量 <code>HADOOP_HOME</code> 和 <code>PATH</code>。</p>
<h2 id="5-启动集群">5 启动集群</h2>
<h3 id="51-格式化-hdfs">5.1 格式化 HDFS</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> ~/bigdata/hadoop-2.7.7
hdfs namenode -format
</code></pre></td></tr></table>
</div>
</div><p><strong>注意：此命令只有在第一次启动前需要执行，目的是格式化 NameNode</strong></p>
<h3 id="52-启动集群">5.2 启动集群</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 启动 HDFS</span>
./sbin/start-dfs.sh
<span class="c1"># 启动 YARN</span>
./sbin/start-yarn.sh
<span class="c1"># 以上两条命令也可以用 ./sbin/start-all.sh 代替</span>
<span class="c1"># 关闭集群 ./sbin/stop-all.sh</span>
</code></pre></td></tr></table>
</div>
</div><p>使用 jps 命令查看服务运行情况</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># master节点中运行的服务</span>
<span class="m">25928</span> SecondaryNameNode
<span class="m">25742</span> NameNode
<span class="m">26387</span> Jps
<span class="m">26078</span> ResourceManager
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># slave节点中运行的服务</span>
<span class="m">24002</span> NodeManager
<span class="m">23899</span> DataNode
<span class="m">24179</span> Jps
</code></pre></td></tr></table>
</div>
</div><h2 id="6-提交示例任务">6 提交示例任务</h2>
<p>如果一切顺利，现在可以向 Hadoop 提交任务了。这里我们使用 Hadoop 自带的实例程序运行 wordcount 任务，以此验证 Hadoop 是否部署成功。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> ~/bigdata/hadoop-2.7.7
<span class="c1"># 把当前路径下的 LICENSE.txt 文件复制到 HDFS 中</span>
hadoop fs -put ./LICENSE.txt /wordcount/input
<span class="c1"># 提交任务，最后两个参数分别指定任务的输入和输出</span>
hadoop jar <span class="nv">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input /wordcount/output
<span class="c1"># 查看输出路径</span>
hadoop fs -ls /wordcount/output
<span class="c1"># 如果一切正常，该路径下包含两个文件</span>
<span class="c1"># 第一个文件是空文件，表示任务运行成功</span>
/wordcount/output/_SUCCESS
<span class="c1"># 第二个文件是输出文件，统计了 LICENSE.txt 中每个单词出现的次数</span>
/wordcount/output/part-r-00000
</code></pre></td></tr></table>
</div>
</div><h2 id="7-遇到的坑">7 遇到的坑</h2>
<h3 id="71-hostname-配置">7.1 hostname 配置</h3>
<p>之前部署 Hadoop 的时候都是在 192.168.7.x 的机器上，那些机器的 hostname 和 hosts 都已经配置好了，直接用就行。但是 192.168.105.x 的这几台机器并没有配好，每台机器的 hostname 都是 ivic。
一开始嫌麻烦就没配，在配置文件里直接填了 IP 地址，结果最后启动集群以后就出现了一个很奇怪的现象——用 jps 命令查看每个节点的服务，一切正常，但在 web ui 里看不到可用的 DataNode，总可用空间是 0。后来看 DataNode 上的日志文件才发现是 hostname 无法解析，不知道为什么 Hadoop 把 IP 地址当作 hostname 了。于是重新配置 hostname，配好以后再重启 Hadoop，问题解决。</p>
<p>hostname 的 配置过程如下（这几台机器上装的是 Ubuntu 18.04，不同系统的配置过程略有区别）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 将该文件中的内容修改为想要的hostname，比如ivic10</span>
sudo vim /etc/hostname
<span class="c1"># 让修改立即生效</span>
hostname ivic10
</code></pre></td></tr></table>
</div>
</div><h3 id="72-format-命令">7.2 format 命令</h3>
<p>在排查上一个问题的过程时，我曾经尝试把 Hadoop 集群停掉然后用 <code>hdfs namenode -format</code> 命令格式化 NameNode，达到“恢复出厂设置”的效果。然而这样做以后再启动 hdfs，原本能启动的 DataNode 现在也启动不了了。浏览 NameNode 的日志发现问题出在 DataNode 的 cluster id 和 NameNode 不一致，所以无法启动。原来 format 命令会为 NameNode 生成一个新的 cluster id，而 DataNode 的 cluster id 信息存储在 <code>dfs.datanode.data.dir</code> 中，并没有发生变化，因此会产生冲突。解决方案是在执行 format 命令之后删除所有 DataNode 的 <code>dfs.datanode.data.dir</code>，也就是 <code>/home/ivic/bigdata/hdfs/data</code>文件夹。</p>
<h3 id="73-日志">7.3 日志</h3>
<p>Hadoop 的日志系统很完善，出了问题在日志里都能找到原因。如果 NameNode 启动不了，就去看 NameNode 的日志，DataNode 启动不了，就去看 DataNode 的日志。日志文件路径为 <code>$HADOOP_HOME/logs</code></p>
<h3 id="74-配置文件的同步">7.4 配置文件的同步</h3>
<p>如果集群用的是 nfs，改一台机器的配置文件其他机器上就全部同步修改好了（不过要注意不要把 <code>dfs.namenode.name.dir</code> 和 <code>dfs.datanode.data.dir</code> 配置到网络文件系统上）。</p>
<p>如果没有 nfs 该怎么办呢，难道每次都要手动修改所有机器上的配置文件吗？不是滴，这时候就需要祭出神器 rsync 了，只要用一条命令就可以把修改推送到其他机器上。</p>
<p>举个例子，比如你刚在 ivic10 上修改了 <code>$HADOOP_HOME/etc/hadoop/</code> 路径下的 core-site.xml，hdfs-site.xml，yarn.xml 三个文件，如何把修改同步到 ivic11 和 ivic12 呢？</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="nb">cd</span> <span class="nv">$HADOOP_HOME</span>/etc
<span class="k">for</span> ip in <span class="m">11</span> 12<span class="p">;</span> <span class="k">do</span> rsync -r hadoop ivic@ivic<span class="si">${</span><span class="nv">ip</span><span class="si">}</span>:/home/ivic/bigdata/hadoop-2.7.7/etc<span class="p">;</span> <span class="k">done</span>
</code></pre></td></tr></table>
</div>
</div><p>搞定。</p>
<h2 id="8-参考">8 参考</h2>
<ol>
<li><a href="https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/FileSystemShell.html">FS Shell Commands</a></li>
<li><a href="https://segmentfault.com/a/1190000015669114">rsync 的使用方法</a></li>
<li><a href="http://www.ityouknow.com/hadoop/2017/07/24/hadoop-cluster-setup.html">Hadoop 分布式集群搭建</a></li>
<li><a href="https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/ClusterSetup.html">Hadoop Cluster Setup</a></li>
</ol>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">邵溧崟</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2019-05-29
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/hadoop/">Hadoop</a>
          <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a>
          <a href="/tags/setup-guide/">Setup Guide</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/flink-cluster-setup/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Flink 集群搭建教程</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/my-first-blog/">
            <span class="next-text nav-default">第一篇博客</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:shaoliyinde@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/sean-pearce" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/seanpearce" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="https://shaoliyin.me/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2019 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">邵溧崟</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
