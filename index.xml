<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>邵溧崟的博客</title>
        <link>https://shaoliyin.me/</link>
        <description>Recent content on 邵溧崟的博客</description>
        <generator>Hugo -- gohugo.io</generator>
        
        <language>zh-cn</language>
        
        <lastBuildDate>Sat, 21 Sep 2019 20:56:58 +0800</lastBuildDate>
        
    
        <atom:link href= "https://shaoliyin.me/index.xml" rel= "self" type= "application/rss+xml" />
    
    
        <item>
            <title>实习面试经历分享</title>
            <link>https://shaoliyin.me/post/interview-experience-sharing/</link>
            <pubDate>Sat, 21 Sep 2019 20:56:58 +0800</pubDate>
            
            <guid>https://shaoliyin.me/post/interview-experience-sharing/</guid>
            <description>&lt;p&gt;两周前连续去面了三家互联网公司的分布式存储开发实习生岗，三家公司分别是头条，Momenta 和旷视，结果是头条挂了其他两家都给了 offer。其实从上个学期开始我就有出去实习的打算，一来是为了提前适应工作环境，在实际应用中锻炼自己的能力，二来则是想去赚点零花钱。但之前一直不太自信，觉得自己啥也不会，去面试就是找虐，直到最近把 MIT 的 6.824 做了一下，至少有了一个可以尬吹的项目，于是决定去试一试。三家公司的简历都是在实习僧上投的，这个网站真的很不错，如果有同学想找实习的话建议试一试（打钱，马上！）。我的三份简历投出去一周之内就都面完了，效率还是很高的。&lt;/p&gt;

&lt;p&gt;其实每次面试结束以后我都会把面试官问到的问题记录下来，但一直懒得整理。今天恰逢周末，又想到自己在面试前也看了很多博主分享的面经，只进不出似乎不太厚道，因此自己的经历也分享出来，供大家参考。&lt;/p&gt;

&lt;h2 id=&#34;字节跳动&#34;&gt;字节跳动&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;面试时间：2019.9.8&lt;/li&gt;
&lt;li&gt;岗位：广告大数据研发实习生&lt;/li&gt;
&lt;li&gt;结果：二面挂&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;一面&#34;&gt;一面&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：不好意思午觉睡过了……简单介绍一下自己吧，我看一下你的简历。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：面试官您好，我叫……（先说了一下自己的学校和专业，然后比较粗略地过了一遍自己简历上的两个项目。）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：可以具体介绍一下云际存储项目吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好的……（讲了一遍上传下载文件的完整流程）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：这个系统的意义是什么呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：一是为了避免云锁定，二是可以提供更高级别的容灾，即使一个云完全挂掉，也不影响用户数据的取回。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：为什么不使用多副本呢？它真的可以降低成本吗？我们来算一下……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（计算多副本和纠删码分块的成本，结果显示采用纠删码分块确实可以降低成本）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我们来聊一聊Raft吧，Raft的实现细节是什么样的？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（从Raft集群启动讲起，每个节点的状态转移条件，以及不同情况下集群的状态，后续提问非常细节，按下不表）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（前两个项目问完，已经过了20-30分钟）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：锁有哪几种？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：互斥锁，信号量……额，不知道了&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：还有原子变量。Python中的字典是线程安全的吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：应该是吧，Python有GIL锁，同一时间只能有一个线程在执行。（其实并不安全，这和GIL锁没关系）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那Java里的哈希表是线程安全的吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：不是，Java里哈希表有专门的线程安全实现。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你的Raft是用Golang写的吧？问一个Golang的问题，如果我要等待一个函数调用一段时间，如果超时则停止等待，应该怎么实现？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：应该是用select和time.after（我前几天正好看了这个，但是没记住具体写法，就有个印象），具体怎么写我不记得了。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：尝试写一下吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好吧……（挣扎着写了一个select语句，大概结构是对的，但是不完整）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你只写了一半啊（面试官并不满意，但看我也写不出来了，就放过我了）。我们做一道题吧。实现pow函数，pow(m, n) = m ** n。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（一上来有点紧张，直接写了个暴力解法，复杂度O(n)，而且n = 0等特殊情况没有考虑到）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：这个实现的时间复杂度是多少？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：O(n)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：有没有更好的解法？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：有……（这时候反应过来了，可以递归调用自身求pow(m, n/2)再平方，也考虑了m = 0, n = 0等特殊情况）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：0的0次方是多少？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：1吧……（我的代码里先判断了m是否为0，如果是则直接返回0，因此有问题）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：OK，我们来考虑一个负载均衡的问题（开始讲问题背景）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（面试官刚开始说，我就表示自己没做过负载均衡）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你不是分布式系统方向的吗？怎么会没涉及过负载均衡？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（跟面试官解释我们实验室的方向）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：哦原来是大数据方向的啊，不好意思我弄错了，那你在学校都上过什么课啊？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：计算机网络，计算机体系结构，算法，机器学习……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：（若有所思）那我们再做一道题吧！（将数组划分为和相等的两部分，leetcode原题）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：这个很明显是背包问题的变种（我没做过这道题，但是面试当天上午正好复习了一下背包问题，所以印象很深刻，花了不到三分钟写出了递推关系式）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：不错，那如果要把数组划分为和相等的三部分呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：额，我想一下（思路错了，想了很久没能想出来，最后面试官走了以后才想到正确解法）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：OK一面就到这里，我去叫一下二面面试官。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好的。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一面总结：面试官看着很年轻，估计也就毕业一两年。面试过程基本就是谈笑风生，一点也不严肃哈哈哈。他走了没一会儿给我打电话说二面面试官在开会，问我可不可以等半个小时，我答应了。&lt;/p&gt;

&lt;h3 id=&#34;二面&#34;&gt;二面&lt;/h3&gt;

&lt;p&gt;每场面试一上来都是自我介绍，之后就不会再提了。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：具体介绍一下云际存储项目。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（略）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：OK，我们来做一道题。（两个有序数组，找第k小的数）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（一时有点懵，说了个双指针的解法，时间复杂度O(k)）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：有没有更好的解法？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：O(k)都不够好的话，只能是O(logk)了（想了一会儿还是没有思路）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那我们稍微换一下，在一个无序数组中找出第k小的数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（心中窃喜，这题我见过）这题可以用快排的思想，每次把一个元素归位，然后就可以知道第k小的元素在前半部分还是后半部分，然后缩小搜索范围，直到找到第k个数。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那你实现一下。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（因为才看过没多久，印象很深，很快就写出来了，面试官可能没见过这种方法，所以思考了一会儿才确定我的实现没问题）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那我们回头看刚才这道题，其实两道题的思想差不多，你再思考一下。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（我靠我以为翻篇儿了，结果还是绕回来了。我当然知道思想差不多啊，时间复杂度要求O(logk)那肯定是二分啊，问题是怎么个二分法）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（之后在面试官的好几次提示之后，我终于似懂非懂地明白了解法，然后面试官让我实现一下，头晕脑胀的我草草写了一个实现，漏洞很多，面试官挑了几个错问了一下，
而我只想赶紧跳过这道题😂）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Q：二面就到这里，我去和三面面试官商量一下。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;二面总结：宇宙条的算法题果然名不虚传，二面上来就是一道hard+难度的题。leetcode上没有原题，但是有一道类似的题——Median of Two Sorted arrays（hard难度），那道面试题相当于是这道题的泛化版。说实话，我觉得这种难度的题除非事先见过类似的，不然根本不可能在面试的短短十几分钟内想出来并bugfree地实现出来。二面面试官走了以后我等了半个多小时，他才回来让我回家等通知（也就是挂了），然后我就如释重负回学校吃饭了。&lt;/p&gt;

&lt;p&gt;总结：我人生中的第一次面试就这样结束了，其实在去之前我就抱着必挂的决心——毕竟是宇宙条啊，怎么可能要我这种咸鱼。但是回过头看，其实也没那么可怕，如果准备的充分一点，完全是有机会的（前提是算法题都能做出来）。另外说一下这次面试的体验，很差，没错是很差。首先，效率低，我约的是下午两点开始面试，离开的时候已经五点了，整整三个小时就面了两场我也是服气。其次，面试竟然在食堂里进行，我刚进去的时候甚至还能闻到饭味儿，而且人特别多，环境很嘈杂，不知道这家公司是怎么考虑的。最后，为什么二面之后要等半个小时才让我回去，早干什么去了，浪费时间。&lt;/p&gt;

&lt;p&gt;字节跳动面试建议：（其实面哪个公司都这些建议）&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;无论面什么岗位，基础知识（操作系统，计算机网络等）一定要扎实，临阵磨枪不可靠，要注重平时的积累和总结。&lt;/li&gt;
&lt;li&gt;至少熟练掌握一门编程语言，了解它的各种特性，建议多买几本好书看看。&lt;/li&gt;
&lt;li&gt;准备1-2个与面试岗位相关的项目，这样就可以和面试官谈笑风生了，如果聊的开心的话会是一个很大的加分项，而且可以拖延面试时间，让面试官少问两道算法题。但必须是自己亲手做的，不然被问住那可就尴尬了。&lt;/li&gt;
&lt;li&gt;算法题要多刷——确保面试时不会碰到陌生题型，常刷——保持手感，常总结——算法题是做不完的，但题型是有限的，要学会举一反三。另外注意刷题效率，不要死扣，刷题这件事注重的是结果，不是过程。30分钟内没做完立马看答案，然后在理解解法的基础上把答案默写出来就可以了。&lt;/li&gt;
&lt;li&gt;字节跳动的算法题偏难，因此要注重刷题，难题也不能放过，每个类型的题目最好都覆盖到。&lt;/li&gt;
&lt;li&gt;心态放平，面过了自然最好，面不过就当它是经验宝宝，每次失败都会让自己变得更强。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;momenta&#34;&gt;Momenta&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;面试时间：2019.9.9&lt;/li&gt;
&lt;li&gt;岗位：分布式存储实习生&lt;/li&gt;
&lt;li&gt;结果：拿到offer&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;一面-1&#34;&gt;一面&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：先自我介绍一下吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：balabala……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：（面试官开始自我介绍，讲他们组目前在做的事，比我说的时间都久，把我整的有点懵）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：哦，嗯，好厉害~&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我看你简历上写了读过MapReduce，GFS，Raft，你来说说GFS吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（我内心一万头草泥马在奔腾，GFS才刚看了个开头，果然不应该把自己不懂的东西写进简历里啊）那个……不好意思，GFS刚看了一半，要不咱聊聊其他两篇？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我们是做存储的，当然要聊GFS了，没事儿，你看到哪儿就说到哪儿吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（好吧面试官是不打算放我一马了，只能硬着头皮上了）GFS集群由两种节点构成，master和chunkserver，master负责元信息管理，chunkserver负责块存储。client读请求处理过程是……，写请求处理过程是……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：写的过程中chunkserver是平等的吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：不是，有一个chunkserver是primary的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：这个身份是如何获得的？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：额……不好意思，我就看到这儿了……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：好吧（面试官也很无奈），那我们来聊聊Raft。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好的（内心狂喜但还是要保持镇定），Raft……（此处略去一万字以及面试官的数个提问）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我们聊聊其他的，你平时用Git吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：用啊，我们实验室内部就有专用的GitLab服务。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那用的是CLI还是GUI客户端呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：那肯定是CLI啊，客户端多不得劲儿。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：好习惯，希望你能坚持下去。你有没有用过一些Git的高级操作，比如……rebase？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：我知道rebase是用来更改提交历史，整理提交历史树的，但是我亲自操作的比较少（其实压根没用过）。我最近用的高级操作……子模块算一个吧。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我们在工作中经常用到k8s和docker，你听说过它们吗？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：听说过，k8s是容器编排工具，docker是容器，也就是轻量化虚拟机。但是没有自己动手实践过。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：OK，我们来做一个题吧。自己设计数据结构，实现LRU Cache，没问题吧？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好的。（Leetcode原题，但是是去年做的，一点都不记得了/(ㄒoㄒ)/~~，不过还好经过提醒写出来了）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：时间到了，一面就到这里，我去叫下一位面试官。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：好的。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一面总结：面试官很年轻，也很好说话，在我表示对GFS不熟的情况下也没有多说什么。最后写算法的时候因为思路不太确定和他沟通了多次，他通过苏格拉底式教学法
（反问的方式）给我了一些提示，很nice~&lt;/p&gt;

&lt;h3 id=&#34;二面-1&#34;&gt;二面&lt;/h3&gt;

&lt;p&gt;（国际惯例，自我介绍）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：我们是做存储的，所以对文件的读写过程要非常了解，你可以介绍一下吗？越详细越好。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：额……这块儿我不是特别熟（提前打预防针），写文件的话，操作系统先和VFS沟通，然后VFS负责和真实的文件系统沟通……（说了几句就说不下去了）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你刚才提到了机械硬盘，那么除此之外硬盘还有哪些种类呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：固态硬盘，还有……带固态缓存的机械硬盘？不知道了。（感觉自己萌蠢萌蠢的）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你平时Linux用的多吗？最喜欢的命令是什么？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：挺多的，最喜欢的命令嘛，ls吧，用的最多（我真是太蠢了，当然要说一个高大上一点的命令啊）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：当前工作目录下有很多目录，每个目录下有很多子目录和文件，要找出所有包含某个字符串的文件应该怎么做？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（开始慌了）用find命令可以搜索文件名，文件内容的话我没用过，可能也是用find命令吧。（其实使用grep）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那接下来做道题吧（你太菜了，我不想跟你说话了）。写一个链表原地排序。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：那就是归并排序呗。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：实现一下（talk is cheap，show me the code）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：写好了（凭借惊人的记忆力😂）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：好的今天面试就到这里，HR一周内会联系你。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;二面总结：感觉面试官问的几个问题都没答好，最后一道算法倒是写的挺快。毕竟自己就是做存储的，这些基础知识应该要掌握，回去努力吧。&lt;/p&gt;

&lt;h3 id=&#34;三面&#34;&gt;三面&lt;/h3&gt;

&lt;p&gt;三面是电话面，主要聊了聊自己的兴趣啊，职业规划啊，人生理想啊（都是面试官问的，我之前其实都没考虑过自己的职业规划），然后面试官介绍了他们目前做的一些工
作，包括分布式存储和计算资源的调度，还表示如果我能来的话肯定可以成长的很快。&lt;/p&gt;

&lt;h2 id=&#34;旷视&#34;&gt;旷视&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;面试时间：2019.9.10&lt;/li&gt;
&lt;li&gt;岗位：分布式存储实习生&lt;/li&gt;
&lt;li&gt;结果：拿到offer&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;一面-2&#34;&gt;一面&lt;/h3&gt;

&lt;p&gt;（自我介绍）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：你的专业是分布式系统，说说对分布式系统的理解。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：我的理解是当一个问题规模太大，单机无法解决的时候，就需要分布式系统。虽然分布式系统扩展了处理问题的能力，但同时也带来了一致性、可用性的问题。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：你的简历里提到了Raft，介绍一下。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（此处省略一万字）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：我们来聊一聊基础一点的问题吧，你知道https吧，它和http有什么区别？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：https是在http之下增加了ssl或tls层的更加安全的网络协议。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：它具体的工作机制是怎么样的呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：那我就从握手说起了可以吗？（给面试官挖坑）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：可以。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：最开始当然是TCP三次握手建立连接，然后开始建立SSL连接，Client发送Hello报文……（详细说了SSL九次握手的过程，面试之前专门背了这个，但前两次面试一直没有问到，这次终于可以表现一下了哈哈哈）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：OK，你刚才提到TCP建立连接需要三次握手，为什么是三次呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：参考这个回答&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：说一下TCP连接断开的过程。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（详细讲了一下四次挥手的过程）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：为什么Client要有TIME_WAIT状态？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：为了防止最后一个ACK包丢失需要重发，否则可能导致服务端连接无法断开。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：死锁发生的条件是什么？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：操作系统里学的，四个条件，请求并保持，循环等待……额，剩下两个忘了&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：最后写一道题吧，实现一个读写锁。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（完全不知道咋实现，用channel实现了一个互斥锁草草了事，后来发现channel本身就是用锁实现的……）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一面总结：面试官很给面子，问了好几个烂大街的问题，正好撞我枪口上了，最后那个锁的问题我还真没关注过，需要学习一下&lt;/p&gt;

&lt;h3 id=&#34;二面-2&#34;&gt;二面&lt;/h3&gt;

&lt;p&gt;（自我介绍）&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q：先来写一道题吧，有没有用过Golang的path包？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：没有……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：没关系，这不重要，请你实现这样一个函数（Leetcode71）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（和面试官讨论了一下输入输出细节，然后比较顺利的写出来了）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那接下来考虑这样一个问题，一个容量为1TB的机械硬盘，写满int64的有序数据，请实现一个函数，输入是一个int64类型的数字，判断这个数字是否出现在上述硬盘中，然后返回一个布尔值。这个函数应该在尽可能短的时间内返回。另外，这个硬盘的延迟时间是10ms，读取速度是100MB/s，你有10GB的内存空间可以使用，在函数的初始化阶段进行的操作不会计入总响应时间。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：既然是有序数据，那么肯定是二分查找。但是这些数据在硬盘上，如果每次二分都要去读硬盘的话延迟太高了，所以要事先把一部分数据放到内存里，二分在内存里进行。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：具体要怎么做呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：每次调用时，函数一次性分散地读n个数，然后在这n个数中进行二分，然后在剩下的两个数之间再分散地读n个数……直到找到输入的数字或者无法继续二分。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：那函数平均需要多少时间才能返回呢？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（算了一会儿发现不对，一次性分散读n个数其实就是随机读n个数，和最naive的做法其实没有本质区别）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：（面试官提醒可以在预处理阶段进行一些操作）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：可以在预处理阶段，每隔128个数字将一个数字读入内存，二分直接在内存里进行，直到找到输入数字可能存在的最小区间，然后再去磁盘里查找。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：有没有进一步优化的空间了？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（脑抽想了个二级索引，其实操作系统中引入二级索引是为了减小索引文件的大小，和这个题没什么关系）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q：机械硬盘的顺序读比随机读快很多，应该利用这一特点，把最后的128个数字一次性读入内存，在内存中做二分查找，这样就可以实现一次调用，只读一次盘了。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A：（好厉害~）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;二面总结：二面其实就问了两个问题，一道算法，一个场景分析题。第二个问题非常有意思，既有用空间换时间的思想，又充分考虑了机械硬盘的特性，学到了~&lt;/p&gt;</description>
        </item>
        
        <item>
            <title>命令行代理小工具——gkd</title>
            <link>https://shaoliyin.me/post/cli-proxy-tool/</link>
            <pubDate>Sun, 21 Jul 2019 16:24:12 +0800</pubDate>
            
            <guid>https://shaoliyin.me/post/cli-proxy-tool/</guid>
            <description>&lt;p&gt;哈罗大家好，转眼间已经到了七月份的尾巴，距离上次更新博客已经差不多两个月了，惭愧惭愧……&lt;/p&gt;

&lt;p&gt;从 GitHub clone 过代码的童鞋肯定都知道，墙内拉代码的速度实在是太慢了，小一点的项目还好，如果代码仓库大小超过了 10MB，那可得等好一会儿了。
有时候运气不佳甚至有可能断线，然后就只能“少侠请重新来过”了。&lt;/p&gt;

&lt;p&gt;但是作为一只专业的程序猿，怎么能被一面矮墙（并不）挡住去路呢。我们先在开发环境中配置代理（按下不表），然后修改一下 git 的配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# http proxy&lt;/span&gt;
git config --global http.https://github.com.proxy http://ip:port
&lt;span class=&#34;c1&#34;&gt;# socks5 proxy&lt;/span&gt;
git config --global http.https://github.com.proxy socks5://ip:port&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;解释一下，上面两条命令是用来修改 git 的代理设置的，&lt;code&gt;http.&lt;/code&gt; 到 &lt;code&gt;.proxy&lt;/code&gt; 中间的字段可以指定要走代理的域名，如果留空的话就相当于全局代理。
最后面的 &lt;code&gt;http://ip:port&lt;/code&gt; 就是代理地址了，两种代理协议的配置只有这里有区别。&lt;/p&gt;

&lt;p&gt;配好之后试着 clone 一下 requests 库：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;shaol@DESKTOP-DT1RASS MINGW64 ~/Documents/Repos
$ git clone https://github.com/kennethreitz/requests.git
Cloning into &lt;span class=&#34;s1&#34;&gt;&amp;#39;requests&amp;#39;&lt;/span&gt;...
remote: Enumerating objects: &lt;span class=&#34;m&#34;&gt;19&lt;/span&gt;, &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;.
remote: Counting objects: &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;% &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;19&lt;/span&gt;/19&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;.
remote: Compressing objects: &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;% &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15&lt;/span&gt;/15&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;.
remote: Total &lt;span class=&#34;m&#34;&gt;23428&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;delta &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, reused &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;delta &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, pack-reused &lt;span class=&#34;m&#34;&gt;23409&lt;/span&gt;
Receiving objects: &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;% &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;23428&lt;/span&gt;/23428&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt;.77 MiB &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;.56 MiB/s, &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;.
Resolving deltas: &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;% &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15352&lt;/span&gt;/15352&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;矮哟不错哟，2.56MB/s 的平均速度基本上什么库都是秒下了。&lt;/p&gt;

&lt;p&gt;既然问题已经解决了，那这篇文章是不是就到此为止了呢？非也非也~ git 的问题的确解决了，但 Linux 系统中还有很多其他的命令行工具需要代理，比如 wget，curl 这些，
怎么才能让它们也走代理呢？比较传统的办法是直接修改当前 shell 的环境变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;http_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://ip:port&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;但是这样做有一个问题：在你手动把环境变量改回来之前，后续执行的所有命令都会遵循这个设置（走代理），失去了灵活性。那么，有没有一种方法可以非常方便地指定一条命令走不走代理呢？&lt;/p&gt;

&lt;p&gt;当然有啦，不然我也不会写（水）这篇文章了哈哈哈。接下来先讲怎么用，再讲为什么。&lt;/p&gt;

&lt;p&gt;首先随便找个地方新建个文件，就叫 &lt;code&gt;gkd&lt;/code&gt; 吧：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;touch gkd&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后把下面的内容复制到这个文件中（记得修改代理地址）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#!/usr/bin/env bash
&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;http_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://ip:port
&lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;再赋予执行权限：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;chmod +x gkd&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;最后，把这个脚本扔到任意一个 PATH 目录下，这里我选了 &lt;code&gt;/usr/bin&lt;/code&gt; 目录&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;move gkd /usr/bin&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;好了，现在配置已经完成，只要在一条命令前加上 &lt;code&gt;gkd&lt;/code&gt;，这条命令的网络流量就会走代理，而且对当前 shell 的环境变量没有任何影响。
我们来测试一下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl ipinfo.io
&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;ip&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;马赛克.39.42.128&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;Beijing&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;region&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;Beijing&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;country&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;CN&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;loc&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;39.9289,116.3880&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;postal&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;100009&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;org&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;AS4847 China Networks Inter-Exchange&amp;#34;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

gkd curl ipinfo.io
&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;ip&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;马赛克.24.185.217&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;city&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;Los Angeles&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;region&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;California&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;country&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;US&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;loc&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;34.0438,-118.2510&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;hostname&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;216.24.185.217.16clouds.com&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;postal&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;90014&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;phone&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;213&amp;#34;&lt;/span&gt;,
  &lt;span class=&#34;s2&#34;&gt;&amp;#34;org&amp;#34;&lt;/span&gt;: &lt;span class=&#34;s2&#34;&gt;&amp;#34;AS25820 IT7 Networks Inc&amp;#34;&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;果然，第二条 curl 命令返回的结果显示我们的访问来自美国，代理成功。以后无论是用 wget 下文件，还是用 go get 拉取依赖，只要在命令前加上 &lt;code&gt;gkd&lt;/code&gt;，它就会很自觉地“搞快点”啦~&lt;/p&gt;

&lt;p&gt;接下来解释一下这个 &lt;code&gt;gkd&lt;/code&gt; 脚本的工作原理。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 指定 shell 解释器为 bash。&lt;/span&gt;
&lt;span class=&#34;cp&#34;&gt;#!/usr/bin/env bash
&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 设置 http_proxy 环境变量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;http_proxy&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;http://ip:port

&lt;span class=&#34;c1&#34;&gt;# 这里是关键&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;@:&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;exec&lt;/code&gt; 是 bash 中的一个内部命令，用于执行 &lt;code&gt;${@:1}&lt;/code&gt; 所表示的命令。&lt;code&gt;${@:1}&lt;/code&gt; 表示传递给这个脚本的所有参数，当执行 &lt;code&gt;gkd curl ipinfo.io&lt;/code&gt; 时，&lt;code&gt;curl&lt;/code&gt; 和 &lt;code&gt;ipinfo.io&lt;/code&gt; 是传递给这个脚本的两个参数，因此 &lt;code&gt;exec ${@:1}&lt;/code&gt; 会被解释为 &lt;code&gt;exec curl ipinfo.io&lt;/code&gt;，而且 &lt;code&gt;exec&lt;/code&gt; 命令可以继承父进程的环境变量，从而实现代理。而执行脚本的进程本身是我们敲命令的 shell 的子进程，修改它的上下文不会影响父进程，因此代理的影响只局限于 &lt;code&gt;gkd curl ipinfo.io&lt;/code&gt; 一条命令。&lt;/p&gt;

&lt;p&gt;感觉自己解释的不是很好，有疑问的童鞋可以看一下下面的两个参考资料。&lt;/p&gt;

&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.gnu.org/software/bash/manual/bash.html&#34;&gt;Bash Reference Manual&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/dd7956aec097&#34;&gt;shell，exec，source执行脚本的区别&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        
        <item>
            <title>Flink 集群搭建教程</title>
            <link>https://shaoliyin.me/post/flink-cluster-setup/</link>
            <pubDate>Wed, 29 May 2019 21:28:14 +0800</pubDate>
            
            <guid>https://shaoliyin.me/post/flink-cluster-setup/</guid>
            <description>&lt;p&gt;这篇文章中的部署环境和上一篇文章完全相同，记录了部署 Flink 集群的过程和遇到的一些问题。&lt;/p&gt;

&lt;h2 id=&#34;1-先决条件&#34;&gt;1 先决条件&lt;/h2&gt;

&lt;p&gt;在部署 Flink 之前，请确认集群的每个节点都符合以下条件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;已安装 Java 1.8.x 或以上版本（推荐 1.8 版本）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;节点两两之间可以 SSH 免密码登陆&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;已部署 Hadoop（如果只是部署 Standalone Cluster 则不需要 Hadoop）&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果你已经按照 &lt;a href=&#34;https://shaoliyin.me/post/hadoop-cluster-setup/&#34;&gt;Hadoop 集群搭建教程&lt;/a&gt; 成功建立了 Hadoop 集群，那么以上条件均已满足。&lt;/p&gt;

&lt;h2 id=&#34;2-下载-flink-二进制文件&#34;&gt;2 下载 Flink 二进制文件&lt;/h2&gt;

&lt;p&gt;在 Flink 的 &lt;a href=&#34;https://flink.apache.org/downloads.html&#34;&gt;下载页面&lt;/a&gt; 中有多个版本可以选择，因为之前选择了 Hadoop 2.7.7 版本，所以这里选择与之对应的 &lt;code&gt;Apache Flink 1.7.2 with Hadoop 2.7&lt;/code&gt; 版本，Scala 版本选择最新的 2.12。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/bigdata
&lt;span class=&#34;c1&#34;&gt;# Apache网站上的镜像太慢，从清华镜像下载&lt;/span&gt;
wget https://mirrors.tuna.tsinghua.edu.cn/apache/flink/flink-1.7.2/flink-1.7.2-bin-hadoop27-scala_2.12.tgz
&lt;span class=&#34;c1&#34;&gt;# 解压到当前文件夹&lt;/span&gt;
tar -xzvf flink-1.7.2-bin-hadoop27-scala_2.12.tgz -C .&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;3-配置-flink&#34;&gt;3 配置 Flink&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;注意：如果只需要部署 Flink on YARN，那么可以跳过这一小节，因为 YARN 会帮你打理好一切。&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 切换到flink配置路径&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ./flink-1.7.2/conf&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-1-flink-conf-yaml&#34;&gt;3.1 flink-conf.yaml&lt;/h3&gt;

&lt;p&gt;将 &lt;code&gt;jobmanager.rpc.address&lt;/code&gt; 指向 master 节点，其他配置项可以按照机器实际硬件情况酌情填写，此处使用默认值。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;c&#34;&gt;# The host/IP of JobManager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;jobmanager.rpc.address&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ivic10&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The heap size for the JobManager JVM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;jobmanager.heap.size&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;1024m&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The heap size for the TaskManager JVM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;taskmanager.heap.size&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;1024m&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;taskmanager.numberOfTaskSlots&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The parallelism used for programs that did not specify and other parallelism.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;parallelism.default&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-2-slaves&#34;&gt;3.2 slaves&lt;/h3&gt;

&lt;p&gt;向 slaves 文件写入 slave 节点的 host/IP 地址&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;ivic11
ivic12&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;4-将配置好的-flink-分发到其他节点&#34;&gt;4 将配置好的 Flink 分发到其他节点&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 需要先在11/12节点上建立 /homne/ivic/bigdata/ 文件夹&lt;/span&gt;
scp -r /home/ivic/bigdata/flink-1.7.2 &lt;span class=&#34;m&#34;&gt;192&lt;/span&gt;.168.105.11:/home/ivic/bigdata/flink-1.7.2
scp -r /home/ivic/bigdata/flink-1.7.2 &lt;span class=&#34;m&#34;&gt;192&lt;/span&gt;.168.105.12:/home/ivic/bigdata/flink-1.7.2&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;5-以-standalone-模式启动-flink&#34;&gt;5 以 Standalone 模式启动 Flink&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$FLINK_HOME&lt;/span&gt;
./bin/start-cluster.sh&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后可以在 &lt;a href=&#34;localhost&#34;&gt;ivic10:8081&lt;/a&gt; 查看 Flink 集群的运行情况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/963d773fly1g0z2d20luij21hc0rz0up.jpg&#34; alt=&#34;standalone web ui&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;./examples&lt;/code&gt; 路径下有许多打包好的示例程序，可以用于验证 Flink 集群是否正常运行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./bin/flink run ./examples/batch/WordCount.jar&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;上面的命令会向 Flink 集群提交一个 wordcount 任务，这个示例程序可以指定输入和输出路径，这里没有指定，因此输入文件为程序自带的一小段文本，结果直接输出在屏幕上。
如果 Flink 集群工作正常，应该会在屏幕上输出以下结果：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-txt&#34; data-lang=&#34;txt&#34;&gt;# 省略前面的输出
(wrong,1)
(you,1)
Program execution finished
Job with JobID d7df697505c1f68d4eda2828b6eb18e2 has finished.
Job Runtime: 3158 ms
Accumulator Results:
- 47b31488879a3449d67aca67f5b75188 (java.util.ArrayList) [170 elements]&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;6-以-flink-on-yarn-模式启动&#34;&gt;6 以 Flink on YARN 模式启动&lt;/h2&gt;

&lt;p&gt;把 Flink 运行在 YARN 上有两种方式，第一种方式是建立一个长期运行的 Flink YARN Session，然后向这个 Session 提交 Flink Job，多个任务同时运行时会共享资源。第二种方式是为单个任务启动一个 Flink 集群，这个任务会独占 Flink 集群的所有资源，任务结束即代表集群被回收。&lt;/p&gt;

&lt;p&gt;另外，Flink on YARN 模式需要系统中设置了 YARN_CONF_DIR 或 HADOOP_CONF_DIR 环境变量，如果未设置，请在 &lt;code&gt;~/.profile&lt;/code&gt; 中加入以下内容，然后使用 &lt;code&gt;source ~/.profile&lt;/code&gt; 命令使修改立即生效。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 在这条命令前定义HADOOP_HOME环境变量&lt;/span&gt;
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;HADOOP_CONF_DIR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;/etc/hadoop&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;6-1-flink-yarn-session&#34;&gt;6.1 Flink YARN Session&lt;/h3&gt;

&lt;p&gt;使用下列命令来启动一个拥有 2 个 TaskManager 的 Flink 集群，每个 TaskManager 有 2 GB 内存，2 个 slot。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./bin/YARN-session.sh -n &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -tm &lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt; -s &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;完整的参数列表如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;Usage:
   Required
     -n,--container &amp;lt;arg&amp;gt;   Number of YARN container to allocate &lt;span class=&#34;o&#34;&gt;(=&lt;/span&gt;Number of Task Managers&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
   Optional
     -D &amp;lt;arg&amp;gt;                        Dynamic properties
     -d,--detached                   Start detached
     -jm,--jobManagerMemory &amp;lt;arg&amp;gt;    Memory &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; JobManager Container with optional unit &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: MB&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
     -nm,--name                      Set a custom name &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; the application on YARN
     -q,--query                      Display available YARN resources &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;memory, cores&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
     -qu,--queue &amp;lt;arg&amp;gt;               Specify YARN queue.
     -s,--slots &amp;lt;arg&amp;gt;                Number of slots per TaskManager
     -tm,--taskManagerMemory &amp;lt;arg&amp;gt;   Memory per TaskManager Container with optional unit &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;default: MB&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
     -z,--zookeeperNamespace &amp;lt;arg&amp;gt;   Namespace to create the Zookeeper sub-paths &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; HA mode&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;启动 YARN Session 以后会输出 JobManager 的 Web Interface 地址，打开以后是这样的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/963d773fly1g0z2d20n7dj21hc0s13zr.jpg&#34; alt=&#34;yarn web ui&#34; /&gt;&lt;/p&gt;

&lt;p&gt;仔细一看，Task Managers，Task Slots 怎么都是 0 呢？难道是哪里出了问题？其实并没有问题，从某个版本开始 Flink 允许动态分配资源，在没有任务的时候不分配 TaskManager。接下来我们就提交一个任务试试。&lt;/p&gt;

&lt;p&gt;因为启动 YARN Session 以后 Flink Client 会一直在前台运行，所以先用 &lt;code&gt;Ctrl + Z&lt;/code&gt; 快捷键把 Client 转到后台，然后再提交任务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./bin/flink run ./examples/batch/WordCount.jar&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;在任务运行期间观察 Web Interface，会发现 Task Managers 变为 1，Task Slots 变为 2 ，与启动集群时指定的参数不符，这是因为 YARN 集群中只有两个 NodeManager，ivic11 和 ivic12，其中一个作为 JobManager，因此只剩一个节点可以作为 TaskManager。&lt;/p&gt;

&lt;p&gt;任务的运行结果和 Standalone 模式下完全一样。&lt;/p&gt;

&lt;h3 id=&#34;6-2-single-flink-job-on-yarn&#34;&gt;6.2 Single Flink job on YARN&lt;/h3&gt;

&lt;p&gt;下面这条命令会为 wordcount 任务启动一个独占的 Flink 集群，任务结束集群即被回收。其中 -m 选项指定 Flink 集群的启动模式，-yn 选项指定 TaskManager 的数目。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./bin/flink run -m YARN-cluster -yn &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; ./examples/batch/WordCount.jar&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;任务的运行结果和 Standalone 模式下完全一样。&lt;/p&gt;

&lt;h2 id=&#34;7-参考&#34;&gt;7 参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/cluster_setup.html&#34;&gt;Standalone Cluster Deployment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ci.apache.org/projects/flink/flink-docs-release-1.7/ops/deployment/YARN_setup.html&#34;&gt;YARN Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/52439318/flink-taskmanagers-do-not-start-until-job-is-submitted-in-YARN-cluster&#34;&gt;Flink TaskManagers do not start in YARN Cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        
        <item>
            <title>Hadoop 集群搭建教程</title>
            <link>https://shaoliyin.me/post/hadoop-cluster-setup/</link>
            <pubDate>Wed, 29 May 2019 19:38:06 +0800</pubDate>
            
            <guid>https://shaoliyin.me/post/hadoop-cluster-setup/</guid>
            <description>&lt;p&gt;这篇文章是我前段时间搭建一个三节点 Hadoop 集群时顺便整理的，集群包含 192.168.105.10 / 11 / 12 三台机器，三台机器的 hostname 分别设为 ivic10 / ivic11 / ivic12，其中第一台机器作为 master，后两台作为 slaves。&lt;/p&gt;

&lt;p&gt;搭建过程中我参考了 Hadoop 官方文档和几篇博客，但还是遇到了一些问题，于是我把整个过程记录了下来，希望可以帮助到大家。&lt;/p&gt;

&lt;h2 id=&#34;1-先决条件&#34;&gt;1 先决条件&lt;/h2&gt;

&lt;p&gt;在开始安装 Hadoop 之前，请确认集群的每台机器上均已安装 JDK1.8（注意是 SunJDK 而不是 OpenJDK），并且已经配置好密钥登陆（服务器两两之间可以无密码SSH登陆）。&lt;/p&gt;

&lt;p&gt;除此之外还需要在三台机器的 &lt;code&gt;/etc/hosts&lt;/code&gt; 文件中写入以下内容（需要root权限）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;192.168.105.10 ivic10
192.168.105.11 ivic11
192.168.105.12 ivic12&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;配置好以后，在任意一台机器上可以用 hostname 无密码 SSH 登陆到另外两台机器上&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 在ivic10上操作&lt;/span&gt;
ssh ivic11
&lt;span class=&#34;c1&#34;&gt;# 如果一切正常，应该可以直接登陆到ivic11上&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;2-下载二进制文件&#34;&gt;2 下载二进制文件&lt;/h2&gt;

&lt;p&gt;在 Hadoop 的 &lt;a href=&#34;https://hadoop.apache.org/releases.html&#34;&gt;release&lt;/a&gt; 页面中有数个版本可以选择，因为后续要在 Hadoop 集群上部署其他应用，所以这里选择兼容性最好的 2.7.7 版本。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;mkdir ~/bigdata
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/bigdata
&lt;span class=&#34;c1&#34;&gt;# Apache网站上的镜像太慢，从清华镜像下载&lt;/span&gt;
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz
&lt;span class=&#34;c1&#34;&gt;# 解压到当前文件夹&lt;/span&gt;
tar -xzvf hadoop-2.7.7.tar.gz -C .&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;3-修改配置文件&#34;&gt;3 修改配置文件&lt;/h2&gt;

&lt;p&gt;首先在 &lt;code&gt;~/.profile&lt;/code&gt; 中添加环境变量&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/home/ivic/bigdata/hadoop-2.7.7
&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;:&lt;span class=&#34;nv&#34;&gt;$HADOOP_HOME&lt;/span&gt;/bin&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;用 &lt;code&gt;source&lt;/code&gt; 命令让环境变量立即生效&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; ~/.profile&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后切换到 Hadoop 的配置文件目录下，开始修改 Hadoop 的配置文件 &lt;code&gt;cd ~/bigdata/hadoop-2.7.7/etc/hadoop&lt;/code&gt;，每一个配置项代表的意义可以参考文末给出的 Hadoop 官方文档。&lt;/p&gt;

&lt;h3 id=&#34;3-1-core-site-xml&#34;&gt;3.1 core-site.xml&lt;/h3&gt;

&lt;p&gt;通过&lt;code&gt;fs.defaultFS&lt;/code&gt;指定 NameNode 的 IP 地址和端口号，通过&lt;code&gt;hadoop.tmp.dir&lt;/code&gt;指定临时文件存放路径&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://ivic10:9000/&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:/tmp/hadoop-2.7.7&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-2-hdfs-site-xml&#34;&gt;3.2 hdfs-site.xml&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;dfs.replication&lt;/code&gt; 指定备份数目为 3，&lt;code&gt;dfs.name.dir&lt;/code&gt; 指定 NameNode 的文件存储路径，&lt;code&gt;dfs.data.dir&lt;/code&gt; 指定 DataNode 的文件存储路径。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:/home/ivic/bigdata/hdfs/name&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;file:/home/ivic/bigdata/hdfs/data&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-3-mapred-site-xml&#34;&gt;3.3 mapred-site.xml&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 将mapred-site.xml.template复制一份&lt;/span&gt;
cp mapred-site.xml.template mapreduce-site.xml&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后修改 &lt;code&gt;mapred-site.xml&lt;/code&gt; 的内容&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;yarn&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-4-yarn-xml&#34;&gt;3.4 yarn.xml&lt;/h3&gt;

&lt;p&gt;配置后两项是因为在部署 Flink on Yarn 的过程中出现了 FlinkYarnSession 无法启动的问题，从 StackOverflow 得知应该在此处加上这两项配置，否则虚拟内存占用会超出限制导致 Flink 无法启动。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;configuration&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;ivic10&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.vmem-check-enabled&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;false&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Whether virtual memory limits will be enforced for containers&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.vmem-pmem-ratio&lt;span class=&#34;nt&#34;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;4&lt;span class=&#34;nt&#34;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;lt;description&amp;gt;&lt;/span&gt;Ratio between virtual memory to physical memory when setting memory limits for containers&lt;span class=&#34;nt&#34;&gt;&amp;lt;/description&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/configuration&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-5-slaves&#34;&gt;3.5 slaves&lt;/h3&gt;

&lt;p&gt;添加 slave 节点的 hostname 到该文件中&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;ivic11
ivic12&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-6-hadoop-env-sh&#34;&gt;3.6 hadoop-env.sh&lt;/h3&gt;

&lt;p&gt;在这里为 Hadoop 设置环境变量&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;/usr/local/jdk1.8.0_201&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;4-分发配置文件&#34;&gt;4 分发配置文件&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 需要先在11/12节点上建立 /homne/ivic/bigdata/ 文件夹&lt;/span&gt;
scp -r /home/ivic/bigdata/hadoop-2.7.7 &lt;span class=&#34;m&#34;&gt;192&lt;/span&gt;.168.105.11:/home/ivic/bigdata/hadoop-2.7.7
scp -r /home/ivic/bigdata/hadoop-2.7.7 &lt;span class=&#34;m&#34;&gt;192&lt;/span&gt;.168.105.12:/home/ivic/bigdata/hadoop-2.7.7&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;然后分别在其他节点上配置环境变量 &lt;code&gt;HADOOP_HOME&lt;/code&gt; 和 &lt;code&gt;PATH&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;5-启动集群&#34;&gt;5 启动集群&lt;/h2&gt;

&lt;h3 id=&#34;5-1-格式化-hdfs&#34;&gt;5.1 格式化 HDFS&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/bigdata/hadoop-2.7.7
hdfs namenode -format&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：此命令只有在第一次启动前需要执行，目的是格式化 NameNode&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-2-启动集群&#34;&gt;5.2 启动集群&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动 HDFS&lt;/span&gt;
./sbin/start-dfs.sh
&lt;span class=&#34;c1&#34;&gt;# 启动 YARN&lt;/span&gt;
./sbin/start-yarn.sh
&lt;span class=&#34;c1&#34;&gt;# 以上两条命令也可以用 ./sbin/start-all.sh 代替&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 关闭集群 ./sbin/stop-all.sh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;使用 jps 命令查看服务运行情况&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# master节点中运行的服务&lt;/span&gt;
&lt;span class=&#34;m&#34;&gt;25928&lt;/span&gt; SecondaryNameNode
&lt;span class=&#34;m&#34;&gt;25742&lt;/span&gt; NameNode
&lt;span class=&#34;m&#34;&gt;26387&lt;/span&gt; Jps
&lt;span class=&#34;m&#34;&gt;26078&lt;/span&gt; ResourceManager&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# slave节点中运行的服务&lt;/span&gt;
&lt;span class=&#34;m&#34;&gt;24002&lt;/span&gt; NodeManager
&lt;span class=&#34;m&#34;&gt;23899&lt;/span&gt; DataNode
&lt;span class=&#34;m&#34;&gt;24179&lt;/span&gt; Jps&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;6-提交示例任务&#34;&gt;6 提交示例任务&lt;/h2&gt;

&lt;p&gt;如果一切顺利，现在可以向 Hadoop 提交任务了。这里我们使用 Hadoop 自带的实例程序运行 wordcount 任务，以此验证 Hadoop 是否部署成功。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; ~/bigdata/hadoop-2.7.7
&lt;span class=&#34;c1&#34;&gt;# 把当前路径下的 LICENSE.txt 文件复制到 HDFS 中&lt;/span&gt;
hadoop fs -put ./LICENSE.txt /wordcount/input
&lt;span class=&#34;c1&#34;&gt;# 提交任务，最后两个参数分别指定任务的输入和输出&lt;/span&gt;
hadoop jar &lt;span class=&#34;nv&#34;&gt;$HADOOP_HOME&lt;/span&gt;/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input /wordcount/output
&lt;span class=&#34;c1&#34;&gt;# 查看输出路径&lt;/span&gt;
hadoop fs -ls /wordcount/output
&lt;span class=&#34;c1&#34;&gt;# 如果一切正常，该路径下包含两个文件&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# 第一个文件是空文件，表示任务运行成功&lt;/span&gt;
/wordcount/output/_SUCCESS
&lt;span class=&#34;c1&#34;&gt;# 第二个文件是输出文件，统计了 LICENSE.txt 中每个单词出现的次数&lt;/span&gt;
/wordcount/output/part-r-00000&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;7-遇到的坑&#34;&gt;7 遇到的坑&lt;/h2&gt;

&lt;h3 id=&#34;7-1-hostname-配置&#34;&gt;7.1 hostname 配置&lt;/h3&gt;

&lt;p&gt;之前部署 Hadoop 的时候都是在 192.168.7.x 的机器上，那些机器的 hostname 和 hosts 都已经配置好了，直接用就行。但是 192.168.105.x 的这几台机器并没有配好，每台机器的 hostname 都是 ivic。
一开始嫌麻烦就没配，在配置文件里直接填了 IP 地址，结果最后启动集群以后就出现了一个很奇怪的现象——用 jps 命令查看每个节点的服务，一切正常，但在 web ui 里看不到可用的 DataNode，总可用空间是 0。后来看 DataNode 上的日志文件才发现是 hostname 无法解析，不知道为什么 Hadoop 把 IP 地址当作 hostname 了。于是重新配置 hostname，配好以后再重启 Hadoop，问题解决。&lt;/p&gt;

&lt;p&gt;hostname 的 配置过程如下（这几台机器上装的是 Ubuntu 18.04，不同系统的配置过程略有区别）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 将该文件中的内容修改为想要的hostname，比如ivic10&lt;/span&gt;
sudo vim /etc/hostname
&lt;span class=&#34;c1&#34;&gt;# 让修改立即生效&lt;/span&gt;
hostname ivic10&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;7-2-format-命令&#34;&gt;7.2 format 命令&lt;/h3&gt;

&lt;p&gt;在排查上一个问题的过程时，我曾经尝试把 Hadoop 集群停掉然后用 &lt;code&gt;hdfs namenode -format&lt;/code&gt; 命令格式化 NameNode，达到“恢复出厂设置”的效果。然而这样做以后再启动 hdfs，原本能启动的 DataNode 现在也启动不了了。浏览 NameNode 的日志发现问题出在 DataNode 的 cluster id 和 NameNode 不一致，所以无法启动。原来 format 命令会为 NameNode 生成一个新的 cluster id，而 DataNode 的 cluster id 信息存储在 &lt;code&gt;dfs.datanode.data.dir&lt;/code&gt; 中，并没有发生变化，因此会产生冲突。解决方案是在执行 format 命令之后删除所有 DataNode 的 &lt;code&gt;dfs.datanode.data.dir&lt;/code&gt;，也就是 &lt;code&gt;/home/ivic/bigdata/hdfs/data&lt;/code&gt;文件夹。&lt;/p&gt;

&lt;h3 id=&#34;7-3-日志&#34;&gt;7.3 日志&lt;/h3&gt;

&lt;p&gt;Hadoop 的日志系统很完善，出了问题在日志里都能找到原因。如果 NameNode 启动不了，就去看 NameNode 的日志，DataNode 启动不了，就去看 DataNode 的日志。日志文件路径为 &lt;code&gt;$HADOOP_HOME/logs&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;7-4-配置文件的同步&#34;&gt;7.4 配置文件的同步&lt;/h3&gt;

&lt;p&gt;如果集群用的是 nfs，改一台机器的配置文件其他机器上就全部同步修改好了（不过要注意不要把 &lt;code&gt;dfs.namenode.name.dir&lt;/code&gt; 和 &lt;code&gt;dfs.datanode.data.dir&lt;/code&gt; 配置到网络文件系统上）。&lt;/p&gt;

&lt;p&gt;如果没有 nfs 该怎么办呢，难道每次都要手动修改所有机器上的配置文件吗？不是滴，这时候就需要祭出神器 rsync 了，只要用一条命令就可以把修改推送到其他机器上。&lt;/p&gt;

&lt;p&gt;举个例子，比如你刚在 ivic10 上修改了 &lt;code&gt;$HADOOP_HOME/etc/hadoop/&lt;/code&gt; 路径下的 core-site.xml，hdfs-site.xml，yarn.xml 三个文件，如何把修改同步到 ivic11 和 ivic12 呢？&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$HADOOP_HOME&lt;/span&gt;/etc
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; ip in &lt;span class=&#34;m&#34;&gt;11&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;12&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; rsync -r hadoop ivic@ivic&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;ip&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;:/home/ivic/bigdata/hadoop-2.7.7/etc&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;done&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;搞定。&lt;/p&gt;

&lt;h2 id=&#34;8-参考&#34;&gt;8 参考&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/FileSystemShell.html&#34;&gt;FS Shell Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://segmentfault.com/a/1190000015669114&#34;&gt;rsync 的使用方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ityouknow.com/hadoop/2017/07/24/hadoop-cluster-setup.html&#34;&gt;Hadoop 分布式集群搭建&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/ClusterSetup.html&#34;&gt;Hadoop Cluster Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        
        <item>
            <title>第一篇博客</title>
            <link>https://shaoliyin.me/post/my-first-blog/</link>
            <pubDate>Thu, 23 May 2019 16:54:12 +0800</pubDate>
            
            <guid>https://shaoliyin.me/post/my-first-blog/</guid>
            <description>&lt;p&gt;很久以来我一直想拥有一个属于自己的博客，但每每想到维护网站的那一堆麻烦事，就失去了折腾的动力。&lt;/p&gt;

&lt;p&gt;最近在参与实验室项目的过程中，接触到很多新技术新知识，愈发地觉得有必要把自己学到的东西记录下来，一方面可以给自己做个备忘，避免重复劳动，另一方面也可以把自己的思考分享到互联网上。因此我用两天时间（其中大部分时间花在了挑选主题上），在 Github Pages 上部署了这个博客。&lt;/p&gt;

&lt;p&gt;本博客不只限于技术内容，我还会在这里分享我的生活和想法。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Happy Blogging !&lt;/strong&gt;&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>